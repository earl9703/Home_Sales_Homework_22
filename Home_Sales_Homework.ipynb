{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75805a-6da9-49fc-8f41-8f21c023e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark and initialize. \n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2216c-a076-47be-b5c7-794529dc4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20799fc-2292-4ba7-a245-3c79a70d9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in the AWS S3 bucket into a DataFrame.\n",
    "from pyspark import SparkFiles\n",
    "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n",
    "\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), sep=\",\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb562e-da03-4944-8e34-8c229ccdf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a temporary view of the DataFrame.\n",
    "#Create a temporary table called home_sales.\n",
    "\n",
    "df.createOrReplaceTempView('home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2e1d6-db45-4a30-9a1a-572305b1fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the average price for a four bedroom house sold in each year rounded to two decimal places?\n",
    "\n",
    "a = \"\"\"\n",
    "SELECT\n",
    "YEAR(date) AS YEAR,\n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM home_sales\n",
    "WHERE bedrooms = 4\n",
    "GROUP BY YEAR\n",
    "ORDER BY YEAR DESC\n",
    "\"\"\"\n",
    "spark.sql(a).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4d6c1-97b9-46c1-bf76-a0aa5db7206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\n",
    "\n",
    "b = \"\"\"\n",
    "SELECT\n",
    "YEAR(date_built) AS YEAR,\n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM home_sales\n",
    "WHERE bedrooms = 3 and bathrooms=3\n",
    "GROUP BY YEAR(date_built)\n",
    "ORDER BY YEAR DESC\n",
    "\"\"\"\n",
    "spark.sql(b).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23c575-904e-43b0-ae91-9a322ce7f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  5. What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors,\n",
    "# and are greater than or equal to 2,000 square feet rounded to two decimal places?\n",
    "\n",
    "\n",
    "c = \"\"\"\n",
    "SELECT\n",
    "YEAR(date_built) AS YEAR_BUILT,\n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM home_sales\n",
    "WHERE bedrooms = 3\n",
    "and bathrooms = 3\n",
    "and sqft_living >= 2000\n",
    "and floors = 2\n",
    "GROUP BY YEAR_BUILT\n",
    "ORDER BY YEAR_BUILT DESC\n",
    "\"\"\"\n",
    "spark.sql(c).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c47239-7328-4635-8490-9d45143549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than\n",
    "# or equal to $350,000? Although this is a small dataset, determine the run time for this query.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "d = \"\"\"\n",
    "SELECT\n",
    "view, \n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM home_sales\n",
    "GROUP BY view\n",
    "HAVING AVG(price) >= 350000\n",
    "ORDER BY view desc\n",
    "\"\"\"\n",
    "spark.sql(d).show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89898124-4b09-479b-8d38-2dffba0327eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Cache the the temporary table home_sales.\n",
    "spark.sql('cache table home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c59089-270b-48b5-a125-7460e98240b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Check if the table is cached.\n",
    "spark.catalog.isCached('home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c2f7b-8116-48a1-9f82-9f98d3fa0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Using the cached data, run the query that filters out the view ratings with average price \n",
    "#  greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "e = \"\"\"\n",
    "SELECT\n",
    "view,\n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM home_sales\n",
    "GROUP BY view\n",
    "HAVING AVG(price) >= 350000\n",
    "ORDER BY view desc\n",
    "\"\"\"\n",
    "spark.sql(e).show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8ffbe-f017-4aad-8e4c-e9730ccb6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Partition by the \"date_built\" field on the formatted parquet home sales data \n",
    "\n",
    "df.write.partitionBy('date_built').parquet('p_home_sales',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abef08-b2a9-45ec-bc19-c4b1a04f3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Read the formatted parquet data.\n",
    "p_df = spark.read.parquet('p_home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5523c1-6983-43b1-a136-9bb81d55dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create a temporary table for the parquet data.\n",
    "\n",
    "p_df.createOrReplaceTempView('parquet_temp_home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f9f0a-59c9-4f14-a985-57a9e53ea803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Run the query that filters out the view ratings with average price of greater than or eqaul to $350,000 \n",
    "# with the parquet DataFrame. Round your average to two decimal places. \n",
    "# Determine the runtime and compare it to the cached version. \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "e = \"\"\"\n",
    "SELECT\n",
    "view,\n",
    "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
    "FROM parquet_temp_home\n",
    "GROUP BY view\n",
    "HAVING AVG(price) >= 350000\n",
    "ORDER BY view desc\n",
    "\"\"\"\n",
    "spark.sql(e).show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b9687-577e-400c-9642-019cb1c92387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Uncache the home_sales temporary table.\n",
    "spark.sql('uncache table home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8c8f0-9937-4dbe-834c-ba4d4404215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Check if the home_sales is no longer cached\n",
    "if spark.catalog.isCached('home_sales'):\n",
    "  print('home_sales is cached')\n",
    "else:\n",
    "  print('not cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799d552-5f50-4ad7-a2e7-e852831e1692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
